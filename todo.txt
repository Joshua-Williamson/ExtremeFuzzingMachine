TODO:
 a few things in queue entries are malloc'd and not freed after the queue is executes.
 we should probably free those after execution? Look at other valgrind things.

 why is timeout going up faster than it can possivly timeoput
 do proper malloc for bufs in each case

 requirements and docker

 Add detailed whitepaper-esque thing

 select edges neighbouring, maybe doesnt work all the time, maybe need to switch it off after a while...

 Remap matrix at frequent intervals, like t-mining, as is taking like 20 minutes at 
 Training seems to be slower too... Maybe the dataloader I propgrammed is actually less effiecint than I thought?

 Error in training at 20800 seeds? -> maybe buggy nocov code

 In mapping -> vstack slow, pad slow... Fixes?

 But it doesn't actually matter too much as this all happens faster than the AFL_havoc stage, so is not really a problem for now.
 Probably bacause all of the data is being loaded twice, think about doing it the other way? Check with timing tool

 Adding table so that seeds and indices arent repeated

 Switch to explored edges that aren't on the path of the particular seed execution

 Smarter nocov cull based on array size. to keep training time under a couple of minutes in extreme 

 Old training function on nnn_old.py:
 Timer unit: 1e-06 s

Total time: 31.975 s
File: /home/ubuntu/NCC_FUZZ/ELM_running/utils/nn_old.py
Function: train at line 448

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   448                                           @profiler
   449                                           def train(optimizer):
   450         5         15.0      3.0      0.0      batch_size=SPLIT_RATIO
   451         5         20.0      4.0      0.0      init = time.time()
   452        10   23284178.0 2328417.8     72.8      for batch_idx, (data, target) in enumerate(train_generate(batch_size)):
   453         5         35.0      7.0      0.0          if args.enable_cuda:
   454                                                       data, target = data.cuda(), target.cuda()
   455        10        235.0     23.5      0.0          data, target = Variable(data,requires_grad=False), \
   456         5        191.0     38.2      0.0                         Variable(target.type(torch.float32),requires_grad=False)
   457         5        178.0     35.6      0.0          optimizer.data=data
   458         5    6440352.0 1288070.4     20.1          optimizer.train(inputs=data, targets=target)
   459         5    1716242.0 343248.4      5.4          output = torch.mm(optimizer.K.T,optimizer.Net)
   460         5     530012.0 106002.4      1.7          acc=accur_1(target,output)
   461                                           
   462         5         40.0      8.0      0.0      ending = time.time()
   463         5       2282.0    456.4      0.0      print('Training time: {:.2f}sec/ Training Accuracy: {:.2f}'.format(ending - init,acc))
   464         5         48.0      9.6      0.0      stats["last training time"] = "{:.2f} sec".format(ending-init)
   465         5        256.0     51.2      0.0      stats["last accuracy"] = "{:.2f}".format(acc*100)
   466         5        933.0    186.6      0.0      update_shm_buff()

And on the new:

otal time: 2.60117 s
File: /home/ubuntu/NCC_FUZZ/ELM_running/utils/nn.py
Function: train at line 216

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   216                                               @profiler
   217                                               # @utils.shm_stats(time_fmt=False)
   218                                               def train(self):
   219                                           
   220         1         11.0     11.0      0.0          st = time.time()
   221                                                   #Build model 
   222         1        259.0    259.0      0.0          optimizer= pseudoInverse(self.corpus_size,C=0.001,L=0,sigma=500.0)
   223                                                   #LoadData
   224         1        771.0    771.0      0.0          data_iter = DataLoader(self.Data, batch_size=self.corpus_size, shuffle=True)
   225         2    2017141.0 1008570.5     77.5          for _,(data,target) in enumerate(data_iter,1):
   226         1         30.0     30.0      0.0              optimizer.data=data
   227         1     433475.0 433475.0     16.7              optimizer.train(inputs=data, targets=target)
   228         1      97785.0  97785.0      3.8              output = torch.mm(optimizer.K.T,optimizer.Net)
   229         1      51504.0  51504.0      2.0              self.accuracy=self.accur_1(target,output)
   230                                           
   231         1          7.0      7.0      0.0          et = time.time()
   232         1        184.0    184.0      0.0          self.last_training = "{:.2f} sec".format(et-st)
   233         1          2.0      2.0      0.0          return optimizer

Theres actually no issue with the new one, I think nocov and readelfs large bitmap is just too much to handle. Will be fixed with smarter nocov culling based on the size of the entire array accounting for the bitmap.
Or perhaps just serving up the array as it is without torch's dataloader rubbish might work better for training. Something to think about for future.

This is the bigger issue, padding and stacking is completely killing the mapping time a temporary fix is doing it at regular intervals. But need to come up with a better way of mapping.


Timer unit: 1e-06 s

Total time: 35.4799 s
File: /home/ubuntu/NCC_FUZZ/ELM_running/utils/nn.py
Function: process_bitmaps at line 66

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    66                                               @profiler
    67                                               # @utils.shm_stats(time_fmt=True)
    68                                               def process_bitmaps(self, initial_map = False):
    69                                           
    70         1      12521.0  12521.0      0.0          self.seeds_list=glob.glob('./seeds/*')
    71                                           
    72         1          4.0      4.0      0.0          if initial_map:
    73         1          4.0      4.0      0.0              to_map = self.seeds_list
    74                                                   else:
    75                                                       to_map = self.get_unmapped_seeds()
    76                                           
    77                                           
    78                                                   #Go through edges of each seed reading through each output file
    79      1595       5401.0      3.4      0.0          for ind,seed in enumerate(to_map):
    80                                                       #Are we the very first?
    81      1594       3070.0      1.9      0.0              first_entry = (ind == 0) * initial_map
    82                                           
    83                                                       #Open our file
    84      1594     147176.0     92.3      0.4              with open("./edges/" + seed.split('/')[-1],'r') as seed_file:
    85      1594      62577.0     39.3      0.2                  seed_info = seed_file.read()
    86                                                           #Ignore hit counts, list of edges we've hit
    87      1594    1272579.0    798.4      3.6                  seed_edges=np.array([int(line.split(':')[0]) for line in seed_info.splitlines()])
    88                                           
    89                                                       #List of edges for this seed that we haven't already got
    90      1594     785345.0    492.7      2.2              unknown_edges = np.invert(np.in1d(seed_edges,self.label))
    91                                                       #Amount of zeros we'll have to append to the bitmap for the other seeds.
    92      1594    3845805.0   2412.7     10.8              pad = sum(unknown_edges)
    93                                           
    94                                                       #If we dont have any seeds processed, we'll make an empty array in the shape of 
    95                                                       #the first map
    96      1594       3391.0      2.1      0.0              if first_entry : self.bitmap=seed_edges
    97                                                       #If not the we'll need to add some zeros to the previous seeds for the new bits
    98      1593       2971.0      1.9      0.0              elif initial_map and ind == 1: self.bitmap=np.pad(self.bitmap,[0, pad], mode='constant') 
    99      1592   12728670.0   7995.4     35.9              else : self.bitmap=np.pad(self.bitmap,[(0,0),(0, pad)], mode='constant')
   100                                           
   101                                                       #We now know the unknown
   102      1594     106387.0     66.7      0.3              self.label = np.append(self.label,seed_edges[unknown_edges])
   103                                                       #Add the seeds bitmap to the array
   104                                                       #If were not in the initial map, just stack the array
   105      1594     843415.0    529.1      2.4              one_hot = np.in1d(self.label,seed_edges)
   106      1594   15289728.0   9592.1     43.1              if not first_entry: self.bitmap = np.vstack(  ( self.bitmap, one_hot.astype('int') ) )
   107                                                       #Write to the emptry array
   108                                           
   109                                                       #Update our dataset size
   110      1594      13085.0      8.2      0.0              self.mapped_seeds += [seed] 
   111      1594     353718.0    221.9      1.0              self.EFM.corpus_size += 1
   112                                           
   113      1594       3875.0      2.4      0.0              if "nocov" in seed:
   114                                                           self.EFM.nocov_size += 1
   115                                           
   116         1        174.0    174.0      0.0          self.EFM.bitmap_size=self.bitmap.shape[1]
   117                                           
   118         1          1.0      1.0      0.0          return
   o


   (neuzz_torch) ubuntu@ip-172-31-37-117:~/NCC_FUZZ/DEMO_DIR/utils$  cd /home/ubuntu/NCC_FUZZ/DEMO_DIR/utils ; /usr/bin/env /home/ubuntu/miniconda3/envs/neuzz_torch/bin/python /home/ubuntu/.vscode-server/extensions/ms-python.python-2022.14.0/pythonFiles/lib/python/debugpy/adapter/../../debugpy/launcher 46321 -- /home/ubuntu/NCC_FUZZ/DEMO_DIR/utils/nn.py -o ../EFM_out ../djpeg 
[2022-09-14 11:15:45,997][utils.py][INFO] Waiting for EFM-fuzz connection
Waiting for EFM-fuzz connection
[2022-09-14 11:15:52,226][utils.py][INFO] Connected to EFM-fuzz on: ('127.0.0.1', 57988)
Connected to EFM-fuzz on: ('127.0.0.1', 57988)
[2022-09-14 11:15:52,227][utils.py][INFO] Shared memory set up
Shared memory set up

[-] PROGRAM ABORT : Target binary times out (adjusting -t may help).
         Location : main(), efm-tmin.c:1248


[-] PROGRAM ABORT : Target binary times out (adjusting -t may help).
         Location : main(), efm-tmin.c:1248


[-] PROGRAM ABORT : Target binary times out (adjusting -t may help).
         Location : main(), efm-tmin.c:1248


[-] PROGRAM ABORT : Target binary times out (adjusting -t may help).
         Location : main(), efm-tmin.c:1248


[-] PROGRAM ABORT : Target binary times out (adjusting -t may help).
         Location : main(), efm-tmin.c:1248

- EFM t-min times out? Which is strange bcause it is on quiet mode, efm-tmin bug?

-Add memory warning for ASAN IF EXITING EARLY?
-FFMPEG: reduce files to way below 10 000 and listen to Pdcst again

Check running args in nn.py are doing it prooperly with the @@...
OOM error with large edge contexts in coomplicated programs??
Doesn't seem to be in flow.py itself. But does occur when the first function in flow is being looped over????

python -m memory_profiler ./utils/flow.py ffmpeg_g 
Filename: ./utils/flow.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   175     41.3 MiB     41.3 MiB           1       @profile
   176                                             def init_work_env(self):
   177     41.5 MiB      0.2 MiB           1           self.strip_search()
   178                                         
   179     41.5 MiB      0.0 MiB           1           if not os.path.exists(self.cf_dir):
   180                                                     os.mkdir(self.cf_dir)
   181     41.5 MiB      0.0 MiB           1           if not os.path.exists(self.dump_target):
   182                                                     cmd = f"objdump -d {self.bin_file} > {self.dump_target}"
   183                                                     os.system(cmd)
   184     41.5 MiB      0.0 MiB           1           if os.path.exists(self.control_flow_target):
   185                                                     return
   186     41.5 MiB      0.0 MiB           1           with open(self.dump_target) as f:
   187    666.2 MiB    624.7 MiB           1               orig_codes = f.readlines()
   188    679.0 MiB      0.0 MiB       30001               for i in range(len(orig_codes)):
   189    679.0 MiB      0.0 MiB       30001                   line = orig_codes[i]
   190    679.0 MiB      0.0 MiB       30001                   if not utils.is_valid_line(line):
   191    678.5 MiB      0.0 MiB         469                       continue
   192    679.0 MiB      0.0 MiB       29532                   if line[0] == ' ':
   193    679.0 MiB      1.5 MiB       29074                       tmp = line.split(':')
   194    679.0 MiB      1.0 MiB       29074                       addr = int(tmp[0], 16)
   195    679.0 MiB      2.3 MiB       29074                       self.addr2asm[addr] = tmp[1].strip()
   196    679.0 MiB      0.0 MiB       29074                       if addr > self.max_asm_addr:
   197    679.0 MiB      0.0 MiB       29074                           self.max_asm_addr = addr
   198    679.0 MiB      0.0 MiB       29074                       if addr < self.min_asm_addr:
   199    666.2 MiB      0.0 MiB           1                           self.min_asm_addr = addr
   200    679.0 MiB      7.2 MiB       29074                       self.next_block[addr] = set()
   201    679.0 MiB      0.3 MiB       29074                       if '__afl_maybe_log' in line:
   202    679.0 MiB      0.0 MiB        1504                           reg_exp = r'0x(.*),'
   203    679.0 MiB      0.2 MiB        1504                           match_obj = re.search(reg_exp, orig_codes[i - 1])
   204    679.0 MiB      0.0 MiB        1504                           if not match_obj:
   205                                                                     print(f"[-]: fatal error: unable to recognize afl_maybe_log id of: {orig_codes[i - 1]}")
   206                                                                     exit(-1)
   207    679.0 MiB      0.3 MiB        1504                           node = Node(int(match_obj.group(1), 16), addr)
   208    679.0 MiB      0.0 MiB        1504                           self.addr2block[addr] = node
   209    679.0 MiB      0.0 MiB        1504                           self.next_block[addr].add(addr)
   210    679.0 MiB      0.0 MiB        1504                           self.nodes.add(node)
   211    679.0 MiB      0.0 MiB       29532                   if line[-2] == ':':
   212    678.5 MiB      0.0 MiB         458                       tmp = line.split(' ')
   213    678.5 MiB      0.0 MiB         458                       addr = int(tmp[0], 16)
   214    678.5 MiB      0.0 MiB         458                       label = tmp[1][:-2]
   215    678.5 MiB      0.0 MiB         458                       self.addr2label[addr] = label
   216    678.5 MiB      0.0 MiB         458                       self.label2addr[label] = addr
   217                                                         
   218    679.0 MiB      0.0 MiB       29532                   if i == 30000:
   219    679.0 MiB      0.0 MiB           1                       break 

 After running flow on ffmpeg for like 30 mins 
               total        used        free      shared  buff/cache   available
Mem:       16383000     3687832     5914584         932     6780584    12352844 ---> from 14100000 when not being used so not too crazy
Swap:             0           0           0

But when being run from nn.py it OOM's

To fuzz with edge context the whole of ffmpeg is too crazy. Even being compiled non-statically

Static:  (neuzz_torch) ubuntu@ip-172-31-37-117:~/NCC_FUZZ/ffmpeg_fuzz$ objdump -d ffmpeg | wc -l
         13412753
         (neuzz_torch) ubuntu@ip-172-31-37-117:~/NCC_FUZZ/ffmpeg_fuzz$ objdump -d ffmpeg_g | wc -l
         13498013

Non-static :
         (neuzz_torch) ubuntu@ip-172-31-37-117:~/NCC_FUZZ/ffmpeg$ objdump -d ffmpeg_g | wc -l
         13498008
         (neuzz_torch) ubuntu@ip-172-31-37-117:~/NCC_FUZZ/ffmpeg$ objdump -d ffmpeg | wc -l
         13412748

These libraries are too large to actually fuzz in thier entirety. You need to only instument one part of the functionalty and fuzz that...?
Or do a dynamic edge context analysis where it only looks one node further than it can see with current coverage?
